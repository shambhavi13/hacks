{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sing a song of sixpence,\n",
      "A pocket full of rye.\n",
      "Four and twenty blackbirds,\n",
      "Baked in a pie.\n",
      "\n",
      "When the pie was opened\n",
      "The birds began to sing;\n",
      "Wasn't that a dainty dish,\n",
      "To set before the king.\n",
      "\n",
      "The king was in his counting house,\n",
      "Counting out his money;\n",
      "The queen was in the parlour,\n",
      "Eating bread and honey.\n",
      "\n",
      "The maid was in the garden,\n",
      "Hanging out the clothes,\n",
      "When down came a blackbird\n",
      "And pecked off her nose.\n"
     ]
    }
   ],
   "source": [
    "raw_text = load_doc('rhyme.txt')\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sing', 'a', 'song', 'of', 'sixpence,', 'A', 'pocket', 'full', 'of', 'rye.', 'Four', 'and', 'twenty', 'blackbirds,', 'Baked', 'in', 'a', 'pie.', 'When', 'the', 'pie', 'was', 'opened', 'The', 'birds', 'began', 'to', 'sing;', \"Wasn't\", 'that', 'a', 'dainty', 'dish,', 'To', 'set', 'before', 'the', 'king.', 'The', 'king', 'was', 'in', 'his', 'counting', 'house,', 'Counting', 'out', 'his', 'money;', 'The', 'queen', 'was', 'in', 'the', 'parlour,', 'Eating', 'bread', 'and', 'honey.', 'The', 'maid', 'was', 'in', 'the', 'garden,', 'Hanging', 'out', 'the', 'clothes,', 'When', 'down', 'came', 'a', 'blackbird', 'And', 'pecked', 'off', 'her', 'nose.']\n",
      "Sing a song of sixpence, A pocket full of rye. Four and twenty blackbirds, Baked in a pie. When the pie was opened The birds began to sing; Wasn't that a dainty dish, To set before the king. The king was in his counting house, Counting out his money; The queen was in the parlour, Eating bread and honey. The maid was in the garden, Hanging out the clothes, When down came a blackbird And pecked off her nose.\n"
     ]
    }
   ],
   "source": [
    "tokens = raw_text.split()\n",
    "raw_text = ' '.join(tokens)\n",
    "print(tokens)\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 399\n"
     ]
    }
   ],
   "source": [
    "# sequence into characters\n",
    "length = 10\n",
    "sequences = list()\n",
    "for i in range(length, len(raw_text)):\n",
    "    seq = raw_text[i-length:i+1]\n",
    "    sequences.append(seq)\n",
    "print('Total sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = 'char_sequences.txt'\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sing a song\n",
      "ing a song \n",
      "ng a song o\n",
      "g a song of\n",
      " a song of \n",
      "a song of s\n",
      " song of si\n",
      "song of six\n",
      "ong of sixp\n",
      "ng of sixpe\n",
      "g of sixpen\n",
      " of sixpenc\n",
      "of sixpence\n",
      "f sixpence,\n",
      " sixpence, \n",
      "sixpence, A\n",
      "ixpence, A \n",
      "xpence, A p\n",
      "pence, A po\n",
      "ence, A poc\n",
      "nce, A pock\n",
      "ce, A pocke\n",
      "e, A pocket\n",
      ", A pocket \n",
      " A pocket f\n",
      "A pocket fu\n",
      " pocket ful\n",
      "pocket full\n",
      "ocket full \n",
      "cket full o\n",
      "ket full of\n",
      "et full of \n",
      "t full of r\n",
      " full of ry\n",
      "full of rye\n",
      "ull of rye.\n",
      "ll of rye. \n",
      "l of rye. F\n",
      " of rye. Fo\n",
      "of rye. Fou\n",
      "f rye. Four\n",
      " rye. Four \n",
      "rye. Four a\n",
      "ye. Four an\n",
      "e. Four and\n",
      ". Four and \n",
      " Four and t\n",
      "Four and tw\n",
      "our and twe\n",
      "ur and twen\n",
      "r and twent\n",
      " and twenty\n",
      "and twenty \n",
      "nd twenty b\n",
      "d twenty bl\n",
      " twenty bla\n",
      "twenty blac\n",
      "wenty black\n",
      "enty blackb\n",
      "nty blackbi\n",
      "ty blackbir\n",
      "y blackbird\n",
      " blackbirds\n",
      "blackbirds,\n",
      "lackbirds, \n",
      "ackbirds, B\n",
      "ckbirds, Ba\n",
      "kbirds, Bak\n",
      "birds, Bake\n",
      "irds, Baked\n",
      "rds, Baked \n",
      "ds, Baked i\n",
      "s, Baked in\n",
      ", Baked in \n",
      " Baked in a\n",
      "Baked in a \n",
      "aked in a p\n",
      "ked in a pi\n",
      "ed in a pie\n",
      "d in a pie.\n",
      " in a pie. \n",
      "in a pie. W\n",
      "n a pie. Wh\n",
      " a pie. Whe\n",
      "a pie. When\n",
      " pie. When \n",
      "pie. When t\n",
      "ie. When th\n",
      "e. When the\n",
      ". When the \n",
      " When the p\n",
      "When the pi\n",
      "hen the pie\n",
      "en the pie \n",
      "n the pie w\n",
      " the pie wa\n",
      "the pie was\n",
      "he pie was \n",
      "e pie was o\n",
      " pie was op\n",
      "pie was ope\n",
      "ie was open\n",
      "e was opene\n",
      " was opened\n",
      "was opened \n",
      "as opened T\n",
      "s opened Th\n",
      " opened The\n",
      "opened The \n",
      "pened The b\n",
      "ened The bi\n",
      "ned The bir\n",
      "ed The bird\n",
      "d The birds\n",
      " The birds \n",
      "The birds b\n",
      "he birds be\n",
      "e birds beg\n",
      " birds bega\n",
      "birds began\n",
      "irds began \n",
      "rds began t\n",
      "ds began to\n",
      "s began to \n",
      " began to s\n",
      "began to si\n",
      "egan to sin\n",
      "gan to sing\n",
      "an to sing;\n",
      "n to sing; \n",
      " to sing; W\n",
      "to sing; Wa\n",
      "o sing; Was\n",
      " sing; Wasn\n",
      "sing; Wasn'\n",
      "ing; Wasn't\n",
      "ng; Wasn't \n",
      "g; Wasn't t\n",
      "; Wasn't th\n",
      " Wasn't tha\n",
      "Wasn't that\n",
      "asn't that \n",
      "sn't that a\n",
      "n't that a \n",
      "'t that a d\n",
      "t that a da\n",
      " that a dai\n",
      "that a dain\n",
      "hat a daint\n",
      "at a dainty\n",
      "t a dainty \n",
      " a dainty d\n",
      "a dainty di\n",
      " dainty dis\n",
      "dainty dish\n",
      "ainty dish,\n",
      "inty dish, \n",
      "nty dish, T\n",
      "ty dish, To\n",
      "y dish, To \n",
      " dish, To s\n",
      "dish, To se\n",
      "ish, To set\n",
      "sh, To set \n",
      "h, To set b\n",
      ", To set be\n",
      " To set bef\n",
      "To set befo\n",
      "o set befor\n",
      " set before\n",
      "set before \n",
      "et before t\n",
      "t before th\n",
      " before the\n",
      "before the \n",
      "efore the k\n",
      "fore the ki\n",
      "ore the kin\n",
      "re the king\n",
      "e the king.\n",
      " the king. \n",
      "the king. T\n",
      "he king. Th\n",
      "e king. The\n",
      " king. The \n",
      "king. The k\n",
      "ing. The ki\n",
      "ng. The kin\n",
      "g. The king\n",
      ". The king \n",
      " The king w\n",
      "The king wa\n",
      "he king was\n",
      "e king was \n",
      " king was i\n",
      "king was in\n",
      "ing was in \n",
      "ng was in h\n",
      "g was in hi\n",
      " was in his\n",
      "was in his \n",
      "as in his c\n",
      "s in his co\n",
      " in his cou\n",
      "in his coun\n",
      "n his count\n",
      " his counti\n",
      "his countin\n",
      "is counting\n",
      "s counting \n",
      " counting h\n",
      "counting ho\n",
      "ounting hou\n",
      "unting hous\n",
      "nting house\n",
      "ting house,\n",
      "ing house, \n",
      "ng house, C\n",
      "g house, Co\n",
      " house, Cou\n",
      "house, Coun\n",
      "ouse, Count\n",
      "use, Counti\n",
      "se, Countin\n",
      "e, Counting\n",
      ", Counting \n",
      " Counting o\n",
      "Counting ou\n",
      "ounting out\n",
      "unting out \n",
      "nting out h\n",
      "ting out hi\n",
      "ing out his\n",
      "ng out his \n",
      "g out his m\n",
      " out his mo\n",
      "out his mon\n",
      "ut his mone\n",
      "t his money\n",
      " his money;\n",
      "his money; \n",
      "is money; T\n",
      "s money; Th\n",
      " money; The\n",
      "money; The \n",
      "oney; The q\n",
      "ney; The qu\n",
      "ey; The que\n",
      "y; The quee\n",
      "; The queen\n",
      " The queen \n",
      "The queen w\n",
      "he queen wa\n",
      "e queen was\n",
      " queen was \n",
      "queen was i\n",
      "ueen was in\n",
      "een was in \n",
      "en was in t\n",
      "n was in th\n",
      " was in the\n",
      "was in the \n",
      "as in the p\n",
      "s in the pa\n",
      " in the par\n",
      "in the parl\n",
      "n the parlo\n",
      " the parlou\n",
      "the parlour\n",
      "he parlour,\n",
      "e parlour, \n",
      " parlour, E\n",
      "parlour, Ea\n",
      "arlour, Eat\n",
      "rlour, Eati\n",
      "lour, Eatin\n",
      "our, Eating\n",
      "ur, Eating \n",
      "r, Eating b\n",
      ", Eating br\n",
      " Eating bre\n",
      "Eating brea\n",
      "ating bread\n",
      "ting bread \n",
      "ing bread a\n",
      "ng bread an\n",
      "g bread and\n",
      " bread and \n",
      "bread and h\n",
      "read and ho\n",
      "ead and hon\n",
      "ad and hone\n",
      "d and honey\n",
      " and honey.\n",
      "and honey. \n",
      "nd honey. T\n",
      "d honey. Th\n",
      " honey. The\n",
      "honey. The \n",
      "oney. The m\n",
      "ney. The ma\n",
      "ey. The mai\n",
      "y. The maid\n",
      ". The maid \n",
      " The maid w\n",
      "The maid wa\n",
      "he maid was\n",
      "e maid was \n",
      " maid was i\n",
      "maid was in\n",
      "aid was in \n",
      "id was in t\n",
      "d was in th\n",
      " was in the\n",
      "was in the \n",
      "as in the g\n",
      "s in the ga\n",
      " in the gar\n",
      "in the gard\n",
      "n the garde\n",
      " the garden\n",
      "the garden,\n",
      "he garden, \n",
      "e garden, H\n",
      " garden, Ha\n",
      "garden, Han\n",
      "arden, Hang\n",
      "rden, Hangi\n",
      "den, Hangin\n",
      "en, Hanging\n",
      "n, Hanging \n",
      ", Hanging o\n",
      " Hanging ou\n",
      "Hanging out\n",
      "anging out \n",
      "nging out t\n",
      "ging out th\n",
      "ing out the\n",
      "ng out the \n",
      "g out the c\n",
      " out the cl\n",
      "out the clo\n",
      "ut the clot\n",
      "t the cloth\n",
      " the clothe\n",
      "the clothes\n",
      "he clothes,\n",
      "e clothes, \n",
      " clothes, W\n",
      "clothes, Wh\n",
      "lothes, Whe\n",
      "othes, When\n",
      "thes, When \n",
      "hes, When d\n",
      "es, When do\n",
      "s, When dow\n",
      ", When down\n",
      " When down \n",
      "When down c\n",
      "hen down ca\n",
      "en down cam\n",
      "n down came\n",
      " down came \n",
      "down came a\n",
      "own came a \n",
      "wn came a b\n",
      "n came a bl\n",
      " came a bla\n",
      "came a blac\n",
      "ame a black\n",
      "me a blackb\n",
      "e a blackbi\n",
      " a blackbir\n",
      "a blackbird\n",
      " blackbird \n",
      "blackbird A\n",
      "lackbird An\n",
      "ackbird And\n",
      "ckbird And \n",
      "kbird And p\n",
      "bird And pe\n",
      "ird And pec\n",
      "rd And peck\n",
      "d And pecke\n",
      " And pecked\n",
      "And pecked \n",
      "nd pecked o\n",
      "d pecked of\n",
      " pecked off\n",
      "pecked off \n",
      "ecked off h\n",
      "cked off he\n",
      "ked off her\n",
      "ed off her \n",
      "d off her n\n",
      " off her no\n",
      "off her nos\n",
      "ff her nose\n",
      "f her nose.\n"
     ]
    }
   ],
   "source": [
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    " \n",
    "# load\n",
    "in_filename = 'char_sequences.txt'\n",
    "raw_text = load_doc(in_filename)\n",
    "print(raw_text)\n",
    "lines = raw_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode seq of chars into integars\n",
    "chars = sorted(list(set(raw_text)))\n",
    "mapping = dict((c,i) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, \"'\": 2, ',': 3, '.': 4, ';': 5, 'A': 6, 'B': 7, 'C': 8, 'E': 9, 'F': 10, 'H': 11, 'S': 12, 'T': 13, 'W': 14, 'a': 15, 'b': 16, 'c': 17, 'd': 18, 'e': 19, 'f': 20, 'g': 21, 'h': 22, 'i': 23, 'k': 24, 'l': 25, 'm': 26, 'n': 27, 'o': 28, 'p': 29, 'q': 30, 'r': 31, 's': 32, 't': 33, 'u': 34, 'w': 35, 'x': 36, 'y': 37}\n"
     ]
    }
   ],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 23, 27, 21, 1, 15, 1, 32, 28, 27, 21], [23, 27, 21, 1, 15, 1, 32, 28, 27, 21, 1], [27, 21, 1, 15, 1, 32, 28, 27, 21, 1, 28], [21, 1, 15, 1, 32, 28, 27, 21, 1, 28, 20], [1, 15, 1, 32, 28, 27, 21, 1, 28, 20, 1], [15, 1, 32, 28, 27, 21, 1, 28, 20, 1, 32], [1, 32, 28, 27, 21, 1, 28, 20, 1, 32, 23], [32, 28, 27, 21, 1, 28, 20, 1, 32, 23, 36], [28, 27, 21, 1, 28, 20, 1, 32, 23, 36, 29], [27, 21, 1, 28, 20, 1, 32, 23, 36, 29, 19], [21, 1, 28, 20, 1, 32, 23, 36, 29, 19, 27], [1, 28, 20, 1, 32, 23, 36, 29, 19, 27, 17], [28, 20, 1, 32, 23, 36, 29, 19, 27, 17, 19], [20, 1, 32, 23, 36, 29, 19, 27, 17, 19, 3], [1, 32, 23, 36, 29, 19, 27, 17, 19, 3, 1], [32, 23, 36, 29, 19, 27, 17, 19, 3, 1, 6], [23, 36, 29, 19, 27, 17, 19, 3, 1, 6, 1], [36, 29, 19, 27, 17, 19, 3, 1, 6, 1, 29], [29, 19, 27, 17, 19, 3, 1, 6, 1, 29, 28], [19, 27, 17, 19, 3, 1, 6, 1, 29, 28, 17], [27, 17, 19, 3, 1, 6, 1, 29, 28, 17, 24], [17, 19, 3, 1, 6, 1, 29, 28, 17, 24, 19], [19, 3, 1, 6, 1, 29, 28, 17, 24, 19, 33], [3, 1, 6, 1, 29, 28, 17, 24, 19, 33, 1], [1, 6, 1, 29, 28, 17, 24, 19, 33, 1, 20], [6, 1, 29, 28, 17, 24, 19, 33, 1, 20, 34], [1, 29, 28, 17, 24, 19, 33, 1, 20, 34, 25], [29, 28, 17, 24, 19, 33, 1, 20, 34, 25, 25], [28, 17, 24, 19, 33, 1, 20, 34, 25, 25, 1], [17, 24, 19, 33, 1, 20, 34, 25, 25, 1, 28], [24, 19, 33, 1, 20, 34, 25, 25, 1, 28, 20], [19, 33, 1, 20, 34, 25, 25, 1, 28, 20, 1], [33, 1, 20, 34, 25, 25, 1, 28, 20, 1, 31], [1, 20, 34, 25, 25, 1, 28, 20, 1, 31, 37], [20, 34, 25, 25, 1, 28, 20, 1, 31, 37, 19], [34, 25, 25, 1, 28, 20, 1, 31, 37, 19, 4], [25, 25, 1, 28, 20, 1, 31, 37, 19, 4, 1], [25, 1, 28, 20, 1, 31, 37, 19, 4, 1, 10], [1, 28, 20, 1, 31, 37, 19, 4, 1, 10, 28], [28, 20, 1, 31, 37, 19, 4, 1, 10, 28, 34], [20, 1, 31, 37, 19, 4, 1, 10, 28, 34, 31], [1, 31, 37, 19, 4, 1, 10, 28, 34, 31, 1], [31, 37, 19, 4, 1, 10, 28, 34, 31, 1, 15], [37, 19, 4, 1, 10, 28, 34, 31, 1, 15, 27], [19, 4, 1, 10, 28, 34, 31, 1, 15, 27, 18], [4, 1, 10, 28, 34, 31, 1, 15, 27, 18, 1], [1, 10, 28, 34, 31, 1, 15, 27, 18, 1, 33], [10, 28, 34, 31, 1, 15, 27, 18, 1, 33, 35], [28, 34, 31, 1, 15, 27, 18, 1, 33, 35, 19], [34, 31, 1, 15, 27, 18, 1, 33, 35, 19, 27], [31, 1, 15, 27, 18, 1, 33, 35, 19, 27, 33], [1, 15, 27, 18, 1, 33, 35, 19, 27, 33, 37], [15, 27, 18, 1, 33, 35, 19, 27, 33, 37, 1], [27, 18, 1, 33, 35, 19, 27, 33, 37, 1, 16], [18, 1, 33, 35, 19, 27, 33, 37, 1, 16, 25], [1, 33, 35, 19, 27, 33, 37, 1, 16, 25, 15], [33, 35, 19, 27, 33, 37, 1, 16, 25, 15, 17], [35, 19, 27, 33, 37, 1, 16, 25, 15, 17, 24], [19, 27, 33, 37, 1, 16, 25, 15, 17, 24, 16], [27, 33, 37, 1, 16, 25, 15, 17, 24, 16, 23], [33, 37, 1, 16, 25, 15, 17, 24, 16, 23, 31], [37, 1, 16, 25, 15, 17, 24, 16, 23, 31, 18], [1, 16, 25, 15, 17, 24, 16, 23, 31, 18, 32], [16, 25, 15, 17, 24, 16, 23, 31, 18, 32, 3], [25, 15, 17, 24, 16, 23, 31, 18, 32, 3, 1], [15, 17, 24, 16, 23, 31, 18, 32, 3, 1, 7], [17, 24, 16, 23, 31, 18, 32, 3, 1, 7, 15], [24, 16, 23, 31, 18, 32, 3, 1, 7, 15, 24], [16, 23, 31, 18, 32, 3, 1, 7, 15, 24, 19], [23, 31, 18, 32, 3, 1, 7, 15, 24, 19, 18], [31, 18, 32, 3, 1, 7, 15, 24, 19, 18, 1], [18, 32, 3, 1, 7, 15, 24, 19, 18, 1, 23], [32, 3, 1, 7, 15, 24, 19, 18, 1, 23, 27], [3, 1, 7, 15, 24, 19, 18, 1, 23, 27, 1], [1, 7, 15, 24, 19, 18, 1, 23, 27, 1, 15], [7, 15, 24, 19, 18, 1, 23, 27, 1, 15, 1], [15, 24, 19, 18, 1, 23, 27, 1, 15, 1, 29], [24, 19, 18, 1, 23, 27, 1, 15, 1, 29, 23], [19, 18, 1, 23, 27, 1, 15, 1, 29, 23, 19], [18, 1, 23, 27, 1, 15, 1, 29, 23, 19, 4], [1, 23, 27, 1, 15, 1, 29, 23, 19, 4, 1], [23, 27, 1, 15, 1, 29, 23, 19, 4, 1, 14], [27, 1, 15, 1, 29, 23, 19, 4, 1, 14, 22], [1, 15, 1, 29, 23, 19, 4, 1, 14, 22, 19], [15, 1, 29, 23, 19, 4, 1, 14, 22, 19, 27], [1, 29, 23, 19, 4, 1, 14, 22, 19, 27, 1], [29, 23, 19, 4, 1, 14, 22, 19, 27, 1, 33], [23, 19, 4, 1, 14, 22, 19, 27, 1, 33, 22], [19, 4, 1, 14, 22, 19, 27, 1, 33, 22, 19], [4, 1, 14, 22, 19, 27, 1, 33, 22, 19, 1], [1, 14, 22, 19, 27, 1, 33, 22, 19, 1, 29], [14, 22, 19, 27, 1, 33, 22, 19, 1, 29, 23], [22, 19, 27, 1, 33, 22, 19, 1, 29, 23, 19], [19, 27, 1, 33, 22, 19, 1, 29, 23, 19, 1], [27, 1, 33, 22, 19, 1, 29, 23, 19, 1, 35], [1, 33, 22, 19, 1, 29, 23, 19, 1, 35, 15], [33, 22, 19, 1, 29, 23, 19, 1, 35, 15, 32], [22, 19, 1, 29, 23, 19, 1, 35, 15, 32, 1], [19, 1, 29, 23, 19, 1, 35, 15, 32, 1, 28], [1, 29, 23, 19, 1, 35, 15, 32, 1, 28, 29], [29, 23, 19, 1, 35, 15, 32, 1, 28, 29, 19], [23, 19, 1, 35, 15, 32, 1, 28, 29, 19, 27], [19, 1, 35, 15, 32, 1, 28, 29, 19, 27, 19], [1, 35, 15, 32, 1, 28, 29, 19, 27, 19, 18], [35, 15, 32, 1, 28, 29, 19, 27, 19, 18, 1], [15, 32, 1, 28, 29, 19, 27, 19, 18, 1, 13], [32, 1, 28, 29, 19, 27, 19, 18, 1, 13, 22], [1, 28, 29, 19, 27, 19, 18, 1, 13, 22, 19], [28, 29, 19, 27, 19, 18, 1, 13, 22, 19, 1], [29, 19, 27, 19, 18, 1, 13, 22, 19, 1, 16], [19, 27, 19, 18, 1, 13, 22, 19, 1, 16, 23], [27, 19, 18, 1, 13, 22, 19, 1, 16, 23, 31], [19, 18, 1, 13, 22, 19, 1, 16, 23, 31, 18], [18, 1, 13, 22, 19, 1, 16, 23, 31, 18, 32], [1, 13, 22, 19, 1, 16, 23, 31, 18, 32, 1], [13, 22, 19, 1, 16, 23, 31, 18, 32, 1, 16], [22, 19, 1, 16, 23, 31, 18, 32, 1, 16, 19], [19, 1, 16, 23, 31, 18, 32, 1, 16, 19, 21], [1, 16, 23, 31, 18, 32, 1, 16, 19, 21, 15], [16, 23, 31, 18, 32, 1, 16, 19, 21, 15, 27], [23, 31, 18, 32, 1, 16, 19, 21, 15, 27, 1], [31, 18, 32, 1, 16, 19, 21, 15, 27, 1, 33], [18, 32, 1, 16, 19, 21, 15, 27, 1, 33, 28], [32, 1, 16, 19, 21, 15, 27, 1, 33, 28, 1], [1, 16, 19, 21, 15, 27, 1, 33, 28, 1, 32], [16, 19, 21, 15, 27, 1, 33, 28, 1, 32, 23], [19, 21, 15, 27, 1, 33, 28, 1, 32, 23, 27], [21, 15, 27, 1, 33, 28, 1, 32, 23, 27, 21], [15, 27, 1, 33, 28, 1, 32, 23, 27, 21, 5], [27, 1, 33, 28, 1, 32, 23, 27, 21, 5, 1], [1, 33, 28, 1, 32, 23, 27, 21, 5, 1, 14], [33, 28, 1, 32, 23, 27, 21, 5, 1, 14, 15], [28, 1, 32, 23, 27, 21, 5, 1, 14, 15, 32], [1, 32, 23, 27, 21, 5, 1, 14, 15, 32, 27], [32, 23, 27, 21, 5, 1, 14, 15, 32, 27, 2], [23, 27, 21, 5, 1, 14, 15, 32, 27, 2, 33], [27, 21, 5, 1, 14, 15, 32, 27, 2, 33, 1], [21, 5, 1, 14, 15, 32, 27, 2, 33, 1, 33], [5, 1, 14, 15, 32, 27, 2, 33, 1, 33, 22], [1, 14, 15, 32, 27, 2, 33, 1, 33, 22, 15], [14, 15, 32, 27, 2, 33, 1, 33, 22, 15, 33], [15, 32, 27, 2, 33, 1, 33, 22, 15, 33, 1], [32, 27, 2, 33, 1, 33, 22, 15, 33, 1, 15], [27, 2, 33, 1, 33, 22, 15, 33, 1, 15, 1], [2, 33, 1, 33, 22, 15, 33, 1, 15, 1, 18], [33, 1, 33, 22, 15, 33, 1, 15, 1, 18, 15], [1, 33, 22, 15, 33, 1, 15, 1, 18, 15, 23], [33, 22, 15, 33, 1, 15, 1, 18, 15, 23, 27], [22, 15, 33, 1, 15, 1, 18, 15, 23, 27, 33], [15, 33, 1, 15, 1, 18, 15, 23, 27, 33, 37], [33, 1, 15, 1, 18, 15, 23, 27, 33, 37, 1], [1, 15, 1, 18, 15, 23, 27, 33, 37, 1, 18], [15, 1, 18, 15, 23, 27, 33, 37, 1, 18, 23], [1, 18, 15, 23, 27, 33, 37, 1, 18, 23, 32], [18, 15, 23, 27, 33, 37, 1, 18, 23, 32, 22], [15, 23, 27, 33, 37, 1, 18, 23, 32, 22, 3], [23, 27, 33, 37, 1, 18, 23, 32, 22, 3, 1], [27, 33, 37, 1, 18, 23, 32, 22, 3, 1, 13], [33, 37, 1, 18, 23, 32, 22, 3, 1, 13, 28], [37, 1, 18, 23, 32, 22, 3, 1, 13, 28, 1], [1, 18, 23, 32, 22, 3, 1, 13, 28, 1, 32], [18, 23, 32, 22, 3, 1, 13, 28, 1, 32, 19], [23, 32, 22, 3, 1, 13, 28, 1, 32, 19, 33], [32, 22, 3, 1, 13, 28, 1, 32, 19, 33, 1], [22, 3, 1, 13, 28, 1, 32, 19, 33, 1, 16], [3, 1, 13, 28, 1, 32, 19, 33, 1, 16, 19], [1, 13, 28, 1, 32, 19, 33, 1, 16, 19, 20], [13, 28, 1, 32, 19, 33, 1, 16, 19, 20, 28], [28, 1, 32, 19, 33, 1, 16, 19, 20, 28, 31], [1, 32, 19, 33, 1, 16, 19, 20, 28, 31, 19], [32, 19, 33, 1, 16, 19, 20, 28, 31, 19, 1], [19, 33, 1, 16, 19, 20, 28, 31, 19, 1, 33], [33, 1, 16, 19, 20, 28, 31, 19, 1, 33, 22], [1, 16, 19, 20, 28, 31, 19, 1, 33, 22, 19], [16, 19, 20, 28, 31, 19, 1, 33, 22, 19, 1], [19, 20, 28, 31, 19, 1, 33, 22, 19, 1, 24], [20, 28, 31, 19, 1, 33, 22, 19, 1, 24, 23], [28, 31, 19, 1, 33, 22, 19, 1, 24, 23, 27], [31, 19, 1, 33, 22, 19, 1, 24, 23, 27, 21], [19, 1, 33, 22, 19, 1, 24, 23, 27, 21, 4], [1, 33, 22, 19, 1, 24, 23, 27, 21, 4, 1], [33, 22, 19, 1, 24, 23, 27, 21, 4, 1, 13], [22, 19, 1, 24, 23, 27, 21, 4, 1, 13, 22], [19, 1, 24, 23, 27, 21, 4, 1, 13, 22, 19], [1, 24, 23, 27, 21, 4, 1, 13, 22, 19, 1], [24, 23, 27, 21, 4, 1, 13, 22, 19, 1, 24], [23, 27, 21, 4, 1, 13, 22, 19, 1, 24, 23], [27, 21, 4, 1, 13, 22, 19, 1, 24, 23, 27], [21, 4, 1, 13, 22, 19, 1, 24, 23, 27, 21], [4, 1, 13, 22, 19, 1, 24, 23, 27, 21, 1], [1, 13, 22, 19, 1, 24, 23, 27, 21, 1, 35], [13, 22, 19, 1, 24, 23, 27, 21, 1, 35, 15], [22, 19, 1, 24, 23, 27, 21, 1, 35, 15, 32], [19, 1, 24, 23, 27, 21, 1, 35, 15, 32, 1], [1, 24, 23, 27, 21, 1, 35, 15, 32, 1, 23], [24, 23, 27, 21, 1, 35, 15, 32, 1, 23, 27], [23, 27, 21, 1, 35, 15, 32, 1, 23, 27, 1], [27, 21, 1, 35, 15, 32, 1, 23, 27, 1, 22], [21, 1, 35, 15, 32, 1, 23, 27, 1, 22, 23], [1, 35, 15, 32, 1, 23, 27, 1, 22, 23, 32], [35, 15, 32, 1, 23, 27, 1, 22, 23, 32, 1], [15, 32, 1, 23, 27, 1, 22, 23, 32, 1, 17], [32, 1, 23, 27, 1, 22, 23, 32, 1, 17, 28], [1, 23, 27, 1, 22, 23, 32, 1, 17, 28, 34], [23, 27, 1, 22, 23, 32, 1, 17, 28, 34, 27], [27, 1, 22, 23, 32, 1, 17, 28, 34, 27, 33], [1, 22, 23, 32, 1, 17, 28, 34, 27, 33, 23], [22, 23, 32, 1, 17, 28, 34, 27, 33, 23, 27], [23, 32, 1, 17, 28, 34, 27, 33, 23, 27, 21], [32, 1, 17, 28, 34, 27, 33, 23, 27, 21, 1], [1, 17, 28, 34, 27, 33, 23, 27, 21, 1, 22], [17, 28, 34, 27, 33, 23, 27, 21, 1, 22, 28], [28, 34, 27, 33, 23, 27, 21, 1, 22, 28, 34], [34, 27, 33, 23, 27, 21, 1, 22, 28, 34, 32], [27, 33, 23, 27, 21, 1, 22, 28, 34, 32, 19], [33, 23, 27, 21, 1, 22, 28, 34, 32, 19, 3], [23, 27, 21, 1, 22, 28, 34, 32, 19, 3, 1], [27, 21, 1, 22, 28, 34, 32, 19, 3, 1, 8], [21, 1, 22, 28, 34, 32, 19, 3, 1, 8, 28], [1, 22, 28, 34, 32, 19, 3, 1, 8, 28, 34], [22, 28, 34, 32, 19, 3, 1, 8, 28, 34, 27], [28, 34, 32, 19, 3, 1, 8, 28, 34, 27, 33], [34, 32, 19, 3, 1, 8, 28, 34, 27, 33, 23], [32, 19, 3, 1, 8, 28, 34, 27, 33, 23, 27], [19, 3, 1, 8, 28, 34, 27, 33, 23, 27, 21], [3, 1, 8, 28, 34, 27, 33, 23, 27, 21, 1], [1, 8, 28, 34, 27, 33, 23, 27, 21, 1, 28], [8, 28, 34, 27, 33, 23, 27, 21, 1, 28, 34], [28, 34, 27, 33, 23, 27, 21, 1, 28, 34, 33], [34, 27, 33, 23, 27, 21, 1, 28, 34, 33, 1], [27, 33, 23, 27, 21, 1, 28, 34, 33, 1, 22], [33, 23, 27, 21, 1, 28, 34, 33, 1, 22, 23], [23, 27, 21, 1, 28, 34, 33, 1, 22, 23, 32], [27, 21, 1, 28, 34, 33, 1, 22, 23, 32, 1], [21, 1, 28, 34, 33, 1, 22, 23, 32, 1, 26], [1, 28, 34, 33, 1, 22, 23, 32, 1, 26, 28], [28, 34, 33, 1, 22, 23, 32, 1, 26, 28, 27], [34, 33, 1, 22, 23, 32, 1, 26, 28, 27, 19], [33, 1, 22, 23, 32, 1, 26, 28, 27, 19, 37], [1, 22, 23, 32, 1, 26, 28, 27, 19, 37, 5], [22, 23, 32, 1, 26, 28, 27, 19, 37, 5, 1], [23, 32, 1, 26, 28, 27, 19, 37, 5, 1, 13], [32, 1, 26, 28, 27, 19, 37, 5, 1, 13, 22], [1, 26, 28, 27, 19, 37, 5, 1, 13, 22, 19], [26, 28, 27, 19, 37, 5, 1, 13, 22, 19, 1], [28, 27, 19, 37, 5, 1, 13, 22, 19, 1, 30], [27, 19, 37, 5, 1, 13, 22, 19, 1, 30, 34], [19, 37, 5, 1, 13, 22, 19, 1, 30, 34, 19], [37, 5, 1, 13, 22, 19, 1, 30, 34, 19, 19], [5, 1, 13, 22, 19, 1, 30, 34, 19, 19, 27], [1, 13, 22, 19, 1, 30, 34, 19, 19, 27, 1], [13, 22, 19, 1, 30, 34, 19, 19, 27, 1, 35], [22, 19, 1, 30, 34, 19, 19, 27, 1, 35, 15], [19, 1, 30, 34, 19, 19, 27, 1, 35, 15, 32], [1, 30, 34, 19, 19, 27, 1, 35, 15, 32, 1], [30, 34, 19, 19, 27, 1, 35, 15, 32, 1, 23], [34, 19, 19, 27, 1, 35, 15, 32, 1, 23, 27], [19, 19, 27, 1, 35, 15, 32, 1, 23, 27, 1], [19, 27, 1, 35, 15, 32, 1, 23, 27, 1, 33], [27, 1, 35, 15, 32, 1, 23, 27, 1, 33, 22], [1, 35, 15, 32, 1, 23, 27, 1, 33, 22, 19], [35, 15, 32, 1, 23, 27, 1, 33, 22, 19, 1], [15, 32, 1, 23, 27, 1, 33, 22, 19, 1, 29], [32, 1, 23, 27, 1, 33, 22, 19, 1, 29, 15], [1, 23, 27, 1, 33, 22, 19, 1, 29, 15, 31], [23, 27, 1, 33, 22, 19, 1, 29, 15, 31, 25], [27, 1, 33, 22, 19, 1, 29, 15, 31, 25, 28], [1, 33, 22, 19, 1, 29, 15, 31, 25, 28, 34], [33, 22, 19, 1, 29, 15, 31, 25, 28, 34, 31], [22, 19, 1, 29, 15, 31, 25, 28, 34, 31, 3], [19, 1, 29, 15, 31, 25, 28, 34, 31, 3, 1], [1, 29, 15, 31, 25, 28, 34, 31, 3, 1, 9], [29, 15, 31, 25, 28, 34, 31, 3, 1, 9, 15], [15, 31, 25, 28, 34, 31, 3, 1, 9, 15, 33], [31, 25, 28, 34, 31, 3, 1, 9, 15, 33, 23], [25, 28, 34, 31, 3, 1, 9, 15, 33, 23, 27], [28, 34, 31, 3, 1, 9, 15, 33, 23, 27, 21], [34, 31, 3, 1, 9, 15, 33, 23, 27, 21, 1], [31, 3, 1, 9, 15, 33, 23, 27, 21, 1, 16], [3, 1, 9, 15, 33, 23, 27, 21, 1, 16, 31], [1, 9, 15, 33, 23, 27, 21, 1, 16, 31, 19], [9, 15, 33, 23, 27, 21, 1, 16, 31, 19, 15], [15, 33, 23, 27, 21, 1, 16, 31, 19, 15, 18], [33, 23, 27, 21, 1, 16, 31, 19, 15, 18, 1], [23, 27, 21, 1, 16, 31, 19, 15, 18, 1, 15], [27, 21, 1, 16, 31, 19, 15, 18, 1, 15, 27], [21, 1, 16, 31, 19, 15, 18, 1, 15, 27, 18], [1, 16, 31, 19, 15, 18, 1, 15, 27, 18, 1], [16, 31, 19, 15, 18, 1, 15, 27, 18, 1, 22], [31, 19, 15, 18, 1, 15, 27, 18, 1, 22, 28], [19, 15, 18, 1, 15, 27, 18, 1, 22, 28, 27], [15, 18, 1, 15, 27, 18, 1, 22, 28, 27, 19], [18, 1, 15, 27, 18, 1, 22, 28, 27, 19, 37], [1, 15, 27, 18, 1, 22, 28, 27, 19, 37, 4], [15, 27, 18, 1, 22, 28, 27, 19, 37, 4, 1], [27, 18, 1, 22, 28, 27, 19, 37, 4, 1, 13], [18, 1, 22, 28, 27, 19, 37, 4, 1, 13, 22], [1, 22, 28, 27, 19, 37, 4, 1, 13, 22, 19], [22, 28, 27, 19, 37, 4, 1, 13, 22, 19, 1], [28, 27, 19, 37, 4, 1, 13, 22, 19, 1, 26], [27, 19, 37, 4, 1, 13, 22, 19, 1, 26, 15], [19, 37, 4, 1, 13, 22, 19, 1, 26, 15, 23], [37, 4, 1, 13, 22, 19, 1, 26, 15, 23, 18], [4, 1, 13, 22, 19, 1, 26, 15, 23, 18, 1], [1, 13, 22, 19, 1, 26, 15, 23, 18, 1, 35], [13, 22, 19, 1, 26, 15, 23, 18, 1, 35, 15], [22, 19, 1, 26, 15, 23, 18, 1, 35, 15, 32], [19, 1, 26, 15, 23, 18, 1, 35, 15, 32, 1], [1, 26, 15, 23, 18, 1, 35, 15, 32, 1, 23], [26, 15, 23, 18, 1, 35, 15, 32, 1, 23, 27], [15, 23, 18, 1, 35, 15, 32, 1, 23, 27, 1], [23, 18, 1, 35, 15, 32, 1, 23, 27, 1, 33], [18, 1, 35, 15, 32, 1, 23, 27, 1, 33, 22], [1, 35, 15, 32, 1, 23, 27, 1, 33, 22, 19], [35, 15, 32, 1, 23, 27, 1, 33, 22, 19, 1], [15, 32, 1, 23, 27, 1, 33, 22, 19, 1, 21], [32, 1, 23, 27, 1, 33, 22, 19, 1, 21, 15], [1, 23, 27, 1, 33, 22, 19, 1, 21, 15, 31], [23, 27, 1, 33, 22, 19, 1, 21, 15, 31, 18], [27, 1, 33, 22, 19, 1, 21, 15, 31, 18, 19], [1, 33, 22, 19, 1, 21, 15, 31, 18, 19, 27], [33, 22, 19, 1, 21, 15, 31, 18, 19, 27, 3], [22, 19, 1, 21, 15, 31, 18, 19, 27, 3, 1], [19, 1, 21, 15, 31, 18, 19, 27, 3, 1, 11], [1, 21, 15, 31, 18, 19, 27, 3, 1, 11, 15], [21, 15, 31, 18, 19, 27, 3, 1, 11, 15, 27], [15, 31, 18, 19, 27, 3, 1, 11, 15, 27, 21], [31, 18, 19, 27, 3, 1, 11, 15, 27, 21, 23], [18, 19, 27, 3, 1, 11, 15, 27, 21, 23, 27], [19, 27, 3, 1, 11, 15, 27, 21, 23, 27, 21], [27, 3, 1, 11, 15, 27, 21, 23, 27, 21, 1], [3, 1, 11, 15, 27, 21, 23, 27, 21, 1, 28], [1, 11, 15, 27, 21, 23, 27, 21, 1, 28, 34], [11, 15, 27, 21, 23, 27, 21, 1, 28, 34, 33], [15, 27, 21, 23, 27, 21, 1, 28, 34, 33, 1], [27, 21, 23, 27, 21, 1, 28, 34, 33, 1, 33], [21, 23, 27, 21, 1, 28, 34, 33, 1, 33, 22], [23, 27, 21, 1, 28, 34, 33, 1, 33, 22, 19], [27, 21, 1, 28, 34, 33, 1, 33, 22, 19, 1], [21, 1, 28, 34, 33, 1, 33, 22, 19, 1, 17], [1, 28, 34, 33, 1, 33, 22, 19, 1, 17, 25], [28, 34, 33, 1, 33, 22, 19, 1, 17, 25, 28], [34, 33, 1, 33, 22, 19, 1, 17, 25, 28, 33], [33, 1, 33, 22, 19, 1, 17, 25, 28, 33, 22], [1, 33, 22, 19, 1, 17, 25, 28, 33, 22, 19], [33, 22, 19, 1, 17, 25, 28, 33, 22, 19, 32], [22, 19, 1, 17, 25, 28, 33, 22, 19, 32, 3], [19, 1, 17, 25, 28, 33, 22, 19, 32, 3, 1], [1, 17, 25, 28, 33, 22, 19, 32, 3, 1, 14], [17, 25, 28, 33, 22, 19, 32, 3, 1, 14, 22], [25, 28, 33, 22, 19, 32, 3, 1, 14, 22, 19], [28, 33, 22, 19, 32, 3, 1, 14, 22, 19, 27], [33, 22, 19, 32, 3, 1, 14, 22, 19, 27, 1], [22, 19, 32, 3, 1, 14, 22, 19, 27, 1, 18], [19, 32, 3, 1, 14, 22, 19, 27, 1, 18, 28], [32, 3, 1, 14, 22, 19, 27, 1, 18, 28, 35], [3, 1, 14, 22, 19, 27, 1, 18, 28, 35, 27], [1, 14, 22, 19, 27, 1, 18, 28, 35, 27, 1], [14, 22, 19, 27, 1, 18, 28, 35, 27, 1, 17], [22, 19, 27, 1, 18, 28, 35, 27, 1, 17, 15], [19, 27, 1, 18, 28, 35, 27, 1, 17, 15, 26], [27, 1, 18, 28, 35, 27, 1, 17, 15, 26, 19], [1, 18, 28, 35, 27, 1, 17, 15, 26, 19, 1], [18, 28, 35, 27, 1, 17, 15, 26, 19, 1, 15], [28, 35, 27, 1, 17, 15, 26, 19, 1, 15, 1], [35, 27, 1, 17, 15, 26, 19, 1, 15, 1, 16], [27, 1, 17, 15, 26, 19, 1, 15, 1, 16, 25], [1, 17, 15, 26, 19, 1, 15, 1, 16, 25, 15], [17, 15, 26, 19, 1, 15, 1, 16, 25, 15, 17], [15, 26, 19, 1, 15, 1, 16, 25, 15, 17, 24], [26, 19, 1, 15, 1, 16, 25, 15, 17, 24, 16], [19, 1, 15, 1, 16, 25, 15, 17, 24, 16, 23], [1, 15, 1, 16, 25, 15, 17, 24, 16, 23, 31], [15, 1, 16, 25, 15, 17, 24, 16, 23, 31, 18], [1, 16, 25, 15, 17, 24, 16, 23, 31, 18, 1], [16, 25, 15, 17, 24, 16, 23, 31, 18, 1, 6], [25, 15, 17, 24, 16, 23, 31, 18, 1, 6, 27], [15, 17, 24, 16, 23, 31, 18, 1, 6, 27, 18], [17, 24, 16, 23, 31, 18, 1, 6, 27, 18, 1], [24, 16, 23, 31, 18, 1, 6, 27, 18, 1, 29], [16, 23, 31, 18, 1, 6, 27, 18, 1, 29, 19], [23, 31, 18, 1, 6, 27, 18, 1, 29, 19, 17], [31, 18, 1, 6, 27, 18, 1, 29, 19, 17, 24], [18, 1, 6, 27, 18, 1, 29, 19, 17, 24, 19], [1, 6, 27, 18, 1, 29, 19, 17, 24, 19, 18], [6, 27, 18, 1, 29, 19, 17, 24, 19, 18, 1], [27, 18, 1, 29, 19, 17, 24, 19, 18, 1, 28], [18, 1, 29, 19, 17, 24, 19, 18, 1, 28, 20], [1, 29, 19, 17, 24, 19, 18, 1, 28, 20, 20], [29, 19, 17, 24, 19, 18, 1, 28, 20, 20, 1], [19, 17, 24, 19, 18, 1, 28, 20, 20, 1, 22], [17, 24, 19, 18, 1, 28, 20, 20, 1, 22, 19], [24, 19, 18, 1, 28, 20, 20, 1, 22, 19, 31], [19, 18, 1, 28, 20, 20, 1, 22, 19, 31, 1], [18, 1, 28, 20, 20, 1, 22, 19, 31, 1, 27], [1, 28, 20, 20, 1, 22, 19, 31, 1, 27, 28], [28, 20, 20, 1, 22, 19, 31, 1, 27, 28, 32], [20, 20, 1, 22, 19, 31, 1, 27, 28, 32, 19], [20, 1, 22, 19, 31, 1, 27, 28, 32, 19, 4]]\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in lines:\n",
    "    # integer encode line\n",
    "    encoded_seq = [mapping[char] for char in line]\n",
    "    # store\n",
    "    sequences.append(encoded_seq)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(mapping)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 23, 27, ..., 32, 28, 27],\n",
       "       [23, 27, 21, ..., 28, 27, 21],\n",
       "       [27, 21,  1, ..., 27, 21,  1],\n",
       "       ...,\n",
       "       [28, 20, 20, ...,  1, 27, 28],\n",
       "       [20, 20,  1, ..., 27, 28, 32],\n",
       "       [20,  1, 22, ..., 28, 32, 19]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/env-gpu/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 75)                34200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 38)                2888      \n",
      "=================================================================\n",
      "Total params: 37,088\n",
      "Trainable params: 37,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/env-gpu/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 1s - loss: 3.6101 - accuracy: 0.0752\n",
      "Epoch 2/100\n",
      " - 0s - loss: 3.4950 - accuracy: 0.2055\n",
      "Epoch 3/100\n",
      " - 0s - loss: 3.1278 - accuracy: 0.1905\n",
      "Epoch 4/100\n",
      " - 0s - loss: 3.0514 - accuracy: 0.1905\n",
      "Epoch 5/100\n",
      " - 0s - loss: 3.0150 - accuracy: 0.1905\n",
      "Epoch 6/100\n",
      " - 0s - loss: 2.9918 - accuracy: 0.1905\n",
      "Epoch 7/100\n",
      " - 0s - loss: 2.9718 - accuracy: 0.1905\n",
      "Epoch 8/100\n",
      " - 0s - loss: 2.9644 - accuracy: 0.1905\n",
      "Epoch 9/100\n",
      " - 0s - loss: 2.9438 - accuracy: 0.1905\n",
      "Epoch 10/100\n",
      " - 0s - loss: 2.9240 - accuracy: 0.1905\n",
      "Epoch 11/100\n",
      " - 0s - loss: 2.9079 - accuracy: 0.1930\n",
      "Epoch 12/100\n",
      " - 0s - loss: 2.8858 - accuracy: 0.1930\n",
      "Epoch 13/100\n",
      " - 0s - loss: 2.8532 - accuracy: 0.2030\n",
      "Epoch 14/100\n",
      " - 0s - loss: 2.8220 - accuracy: 0.2155\n",
      "Epoch 15/100\n",
      " - 0s - loss: 2.7975 - accuracy: 0.2206\n",
      "Epoch 16/100\n",
      " - 0s - loss: 2.7693 - accuracy: 0.2581\n",
      "Epoch 17/100\n",
      " - 0s - loss: 2.7277 - accuracy: 0.2281\n",
      "Epoch 18/100\n",
      " - 0s - loss: 2.6877 - accuracy: 0.2757\n",
      "Epoch 19/100\n",
      " - 0s - loss: 2.6469 - accuracy: 0.2607\n",
      "Epoch 20/100\n",
      " - 0s - loss: 2.6048 - accuracy: 0.2732\n",
      "Epoch 21/100\n",
      " - 0s - loss: 2.5718 - accuracy: 0.2657\n",
      "Epoch 22/100\n",
      " - 0s - loss: 2.5540 - accuracy: 0.2757\n",
      "Epoch 23/100\n",
      " - 0s - loss: 2.5018 - accuracy: 0.2857\n",
      "Epoch 24/100\n",
      " - 0s - loss: 2.4564 - accuracy: 0.2982\n",
      "Epoch 25/100\n",
      " - 0s - loss: 2.4054 - accuracy: 0.3158\n",
      "Epoch 26/100\n",
      " - 0s - loss: 2.3766 - accuracy: 0.3308\n",
      "Epoch 27/100\n",
      " - 0s - loss: 2.3308 - accuracy: 0.3283\n",
      "Epoch 28/100\n",
      " - 0s - loss: 2.2851 - accuracy: 0.3434\n",
      "Epoch 29/100\n",
      " - 0s - loss: 2.2495 - accuracy: 0.3509\n",
      "Epoch 30/100\n",
      " - 0s - loss: 2.2206 - accuracy: 0.3759\n",
      "Epoch 31/100\n",
      " - 0s - loss: 2.1691 - accuracy: 0.3910\n",
      "Epoch 32/100\n",
      " - 0s - loss: 2.1603 - accuracy: 0.3985\n",
      "Epoch 33/100\n",
      " - 0s - loss: 2.1113 - accuracy: 0.3885\n",
      "Epoch 34/100\n",
      " - 0s - loss: 2.0657 - accuracy: 0.4386\n",
      "Epoch 35/100\n",
      " - 0s - loss: 2.0107 - accuracy: 0.4336\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.9794 - accuracy: 0.4336\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.9239 - accuracy: 0.4787\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.9011 - accuracy: 0.4737\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.8498 - accuracy: 0.5038\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.8445 - accuracy: 0.5013\n",
      "Epoch 41/100\n",
      " - 0s - loss: 1.7938 - accuracy: 0.4962\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.7673 - accuracy: 0.5188\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.7305 - accuracy: 0.5213\n",
      "Epoch 44/100\n",
      " - 0s - loss: 1.6576 - accuracy: 0.5664\n",
      "Epoch 45/100\n",
      " - 0s - loss: 1.6264 - accuracy: 0.5564\n",
      "Epoch 46/100\n",
      " - 0s - loss: 1.6007 - accuracy: 0.5789\n",
      "Epoch 47/100\n",
      " - 0s - loss: 1.5519 - accuracy: 0.5764\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.5231 - accuracy: 0.5840\n",
      "Epoch 49/100\n",
      " - 0s - loss: 1.4858 - accuracy: 0.5990\n",
      "Epoch 50/100\n",
      " - 0s - loss: 1.4578 - accuracy: 0.5890\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.4067 - accuracy: 0.6291\n",
      "Epoch 52/100\n",
      " - 0s - loss: 1.3764 - accuracy: 0.6190\n",
      "Epoch 53/100\n",
      " - 0s - loss: 1.3548 - accuracy: 0.6441\n",
      "Epoch 54/100\n",
      " - 0s - loss: 1.3007 - accuracy: 0.6541\n",
      "Epoch 55/100\n",
      " - 0s - loss: 1.2751 - accuracy: 0.6717\n",
      "Epoch 56/100\n",
      " - 0s - loss: 1.2319 - accuracy: 0.6892\n",
      "Epoch 57/100\n",
      " - 0s - loss: 1.1843 - accuracy: 0.7093\n",
      "Epoch 58/100\n",
      " - 0s - loss: 1.1401 - accuracy: 0.7268\n",
      "Epoch 59/100\n",
      " - 0s - loss: 1.1180 - accuracy: 0.7318\n",
      "Epoch 60/100\n",
      " - 0s - loss: 1.0788 - accuracy: 0.7469\n",
      "Epoch 61/100\n",
      " - 0s - loss: 1.0464 - accuracy: 0.7694\n",
      "Epoch 62/100\n",
      " - 0s - loss: 1.0085 - accuracy: 0.7794\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.9623 - accuracy: 0.8045\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.9310 - accuracy: 0.8095\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.9035 - accuracy: 0.8271\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.8636 - accuracy: 0.8346\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.8343 - accuracy: 0.8546\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.8157 - accuracy: 0.8471\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.7841 - accuracy: 0.8371\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.7499 - accuracy: 0.8797\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.7246 - accuracy: 0.8922\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.7004 - accuracy: 0.8872\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.6955 - accuracy: 0.8872\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.6598 - accuracy: 0.8972\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.6178 - accuracy: 0.9098\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.5915 - accuracy: 0.9198\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.5631 - accuracy: 0.9298\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.5489 - accuracy: 0.9348\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.5173 - accuracy: 0.9348\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.5143 - accuracy: 0.9323\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4968 - accuracy: 0.9398\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4705 - accuracy: 0.9499\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4474 - accuracy: 0.9599\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4357 - accuracy: 0.9674\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4127 - accuracy: 0.9699\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.3929 - accuracy: 0.9699\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3746 - accuracy: 0.9774\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.3626 - accuracy: 0.9799\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3535 - accuracy: 0.9825\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.3436 - accuracy: 0.9825\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.3188 - accuracy: 0.9850\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.3065 - accuracy: 0.9774\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.3002 - accuracy: 0.9875\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.2916 - accuracy: 0.9799\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.2689 - accuracy: 0.9875\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.2573 - accuracy: 0.9925\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.2528 - accuracy: 0.9875\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.2434 - accuracy: 0.9900\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.2400 - accuracy: 0.9875\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.2329 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fcaacd435f8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "from pickle import dump\n",
    "model.save('model.h5')\n",
    "# save the mapping\n",
    "dump(mapping, open('mapping.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fcaac16a2b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence of characters with a language model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of characters\n",
    "    for _ in range(n_chars):\n",
    "        # encode the characters as integers\n",
    "        encoded = [mapping[char] for char in in_text]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # one hot encode\n",
    "        encoded = to_categorical(encoded, num_classes=len(mapping))\n",
    "        # predict character\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # reverse map integer to character\n",
    "        out_char = ''\n",
    "        for char, index in mapping.items():\n",
    "            if index == yhat:\n",
    "                out_char = char\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += char\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sing a song of sixpence, A poc\n",
      "king was in his pounty Whll oo\n",
      "hello worl eFpeaan , Atkggcrrd\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "\n",
    "model = load_model('model.h5')\n",
    "# load the mapping\n",
    " \n",
    "# test start of rhyme\n",
    "print(generate_seq(model, mapping, 10, 'Sing a son', 20))\n",
    "# test mid-line\n",
    "print(generate_seq(model, mapping, 10, 'king was i', 20))\n",
    "# test not in original\n",
    "print(generate_seq(model, mapping, 10, 'hello worl', 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section lists some ideas for extending the tutorial that you may wish to explore.\n",
    "\n",
    "#Padding. Update the example to provides sequences line by line only and use padding to fill out each sequence to the maximum line length.\n",
    "#Sequence Length. Experiment with different sequence lengths and see how they impact the behavior of the model.\n",
    "#Tune Model. Experiment with different model configurations, such as the number of memory cells and epochs, and try to develop a better model for fewer resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env-gpu)",
   "language": "python",
   "name": "env-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
