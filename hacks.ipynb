{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM MODEL \n",
    "\n",
    "Used character sequences which make up the name as our feature variable, with gender as labels. Used a stack LSTM model and a final dense layer with softmax activation (many-to-one setup). categorical cross-entropy loss is used with adam optimizer. A 20% dropout layer is added for regularization to avoid over-fitting.\n",
    "\n",
    "This Model is trained on *GPU instance* took 5 mins to run 10 epochs.\n",
    "\n",
    "This model gave the **test accuracy 100%**. The model might be overfitting. Try hyperparam tuning to reduce it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99093, 3)\n",
      "    Person Name Gender Train/Test\n",
      "0         -minu   Male       Test\n",
      "1  (.)p(...)nin   Male      Train\n",
      "2   12th Planet   Male      Train\n",
      "3      2 Chainz   Male      Train\n",
      "4       50 Cent   Male      Train\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/allnames.tsv', sep='\\t')\n",
    "df = df.drop(columns='Person ID')\n",
    "df = df.drop_duplicates(subset=\"Person Name\")\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non latin chars\n",
    "\n",
    "def clean_col(df, col_list, non_latin):\n",
    "    df = df.copy().dropna()\n",
    "    for col in col_list:\n",
    "        # df[col] = df[col].str.strip()\n",
    "        # df[col] = df[col].str.replace(r'([^\\s\\w]|_)+', '')\n",
    "        # df[col] = df[col].apply(lambda x: x.encode(\"ascii\", errors=\"ignore\").decode())\n",
    "\n",
    "        contains_non_latin = df[col].str.contains(non_latin)\n",
    "        series = df[col].apply(\n",
    "            lambda x: ''.join([c for c in\n",
    "                               re.sub(r'\\s+', ' ', x).strip()]).strip())\n",
    "        df[col] = series\n",
    "\n",
    "        # Get the mask of overly long utterances\n",
    "        #keep = series.str.encode(encoding='utf-8').apply(len) < max_len\n",
    "        df = df[(series != '') &\n",
    "                (series != 'None') &\n",
    "                (~contains_non_latin)]\n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Train/Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-minu</td>\n",
       "      <td>Male</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(.)p(...)nin</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12th Planet</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 Chainz</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50 Cent</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A-Lin</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A-Mei</td>\n",
       "      <td>Female</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A. C. Crispin</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A. C. Newman</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A. D. Walsh</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A. E. Johann</td>\n",
       "      <td>Male</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A. G. Perarivalan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A. H. Salunkhe</td>\n",
       "      <td>Male</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A. J. Buckley</td>\n",
       "      <td>Male</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A. J. Cook</td>\n",
       "      <td>Female</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A. J. Langer</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A. L. Abdul Majeed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A. L. Kennedy</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A. M. Homes</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A. M. Willner</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A. O. Scott</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A. P. J. Abdul Kalam</td>\n",
       "      <td>Male</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A. Paul Weber</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A. R. Rahman</td>\n",
       "      <td>Male</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A. S. Byatt</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A. Tóth Sándor</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A. Vellayan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A.geh Wirklich?</td>\n",
       "      <td>Male</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A.J. Styles</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A.R. Chughtai</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99969</th>\n",
       "      <td>Zuzana Tomas</td>\n",
       "      <td>Female</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99970</th>\n",
       "      <td>Zuzana Tryznová</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99971</th>\n",
       "      <td>Zuzana Vejvodová</td>\n",
       "      <td>Female</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99972</th>\n",
       "      <td>Zuzana Vojířová von Vacovice</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>Zuzana Žirková</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>Zuzana Zlochová</td>\n",
       "      <td>Female</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>Zvi Aharoni</td>\n",
       "      <td>Male</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>Zvjezdan Misimović</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>Zvonimir Kavurić</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>Zwetana Krastewa</td>\n",
       "      <td>Female</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>Žydrūnas Ilgauskas</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99980</th>\n",
       "      <td>Zygmunt Anczok</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99981</th>\n",
       "      <td>Zygmunt Andrychiewicz</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>Zygmunt Bauman</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>Zygmunt Chmielewski</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>Zygmunt Chychła</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>Zygmunt Hübner</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>Zygmunt Kęstowicz</td>\n",
       "      <td>Male</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>Zygmunt Smalcerz</td>\n",
       "      <td>Male</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>Zypora Frank</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>Zyta Gilowska</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>Zyta Rudzka</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>Þóra Björg Helgadóttir</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>Þórey Rósa Stéfansdóttir</td>\n",
       "      <td>Female</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>Þorgerður Katrín Gunnarsdóttir</td>\n",
       "      <td>Female</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>Þórhildur Þorleifsdóttir</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Þórunn Helga Jónsdóttir</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Þórunn Sveinbjarnardóttir</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Þurið Þorkilsdóttir</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Þuríður Backman</td>\n",
       "      <td>Female</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99056 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Person Name  Gender Train/Test\n",
       "0                               -minu    Male       Test\n",
       "1                        (.)p(...)nin    Male      Train\n",
       "2                         12th Planet    Male      Train\n",
       "3                            2 Chainz    Male      Train\n",
       "4                             50 Cent    Male      Train\n",
       "5                               A-Lin  Female      Train\n",
       "6                               A-Mei  Female       Test\n",
       "7                       A. C. Crispin  Female      Train\n",
       "8                        A. C. Newman    Male      Train\n",
       "9                         A. D. Walsh    Male      Train\n",
       "10                       A. E. Johann    Male       Test\n",
       "11                  A. G. Perarivalan    Male      Train\n",
       "12                     A. H. Salunkhe    Male       Test\n",
       "13                      A. J. Buckley    Male       Test\n",
       "14                         A. J. Cook  Female       Test\n",
       "15                       A. J. Langer  Female      Train\n",
       "16                 A. L. Abdul Majeed    Male      Train\n",
       "17                      A. L. Kennedy  Female      Train\n",
       "18                        A. M. Homes  Female      Train\n",
       "19                      A. M. Willner    Male      Train\n",
       "20                        A. O. Scott    Male      Train\n",
       "21               A. P. J. Abdul Kalam    Male       Test\n",
       "22                      A. Paul Weber    Male      Train\n",
       "23                       A. R. Rahman    Male       Test\n",
       "24                        A. S. Byatt  Female      Train\n",
       "25                     A. Tóth Sándor    Male      Train\n",
       "26                        A. Vellayan    Male      Train\n",
       "27                    A.geh Wirklich?    Male       Test\n",
       "28                        A.J. Styles    Male      Train\n",
       "29                      A.R. Chughtai    Male      Train\n",
       "...                               ...     ...        ...\n",
       "99969                    Zuzana Tomas  Female       Test\n",
       "99970                 Zuzana Tryznová  Female      Train\n",
       "99971                Zuzana Vejvodová  Female       Test\n",
       "99972    Zuzana Vojířová von Vacovice  Female      Train\n",
       "99973                  Zuzana Žirková  Female      Train\n",
       "99974                 Zuzana Zlochová  Female       Test\n",
       "99975                     Zvi Aharoni    Male       Test\n",
       "99976              Zvjezdan Misimović    Male      Train\n",
       "99977                Zvonimir Kavurić    Male      Train\n",
       "99978                Zwetana Krastewa  Female       Test\n",
       "99979              Žydrūnas Ilgauskas    Male      Train\n",
       "99980                  Zygmunt Anczok    Male      Train\n",
       "99981           Zygmunt Andrychiewicz    Male      Train\n",
       "99982                  Zygmunt Bauman    Male      Train\n",
       "99983             Zygmunt Chmielewski    Male      Train\n",
       "99984                 Zygmunt Chychła    Male      Train\n",
       "99985                  Zygmunt Hübner    Male      Train\n",
       "99986               Zygmunt Kęstowicz    Male      Train\n",
       "99987                Zygmunt Smalcerz    Male       Test\n",
       "99988                    Zypora Frank  Female      Train\n",
       "99989                   Zyta Gilowska  Female      Train\n",
       "99990                     Zyta Rudzka  Female      Train\n",
       "99991          Þóra Björg Helgadóttir  Female      Train\n",
       "99992        Þórey Rósa Stéfansdóttir  Female       Test\n",
       "99993  Þorgerður Katrín Gunnarsdóttir  Female       Test\n",
       "99994        Þórhildur Þorleifsdóttir  Female      Train\n",
       "99995         Þórunn Helga Jónsdóttir  Female      Train\n",
       "99996       Þórunn Sveinbjarnardóttir  Female      Train\n",
       "99997             Þurið Þorkilsdóttir  Female      Train\n",
       "99998                 Þuríður Backman  Female      Train\n",
       "\n",
       "[99056 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = ['Person Name']\n",
    "non_latin = r'[^\\x00-\\x7F\\x80-\\xFF\\u0100-\\u017F\\u0180-\\u024F\\u1E00-\\u1EFF]'\n",
    "clean_col(df, col_list, non_latin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non ascii chars\n",
    "def remove_non_ascii(text):\n",
    "    return ''.join(i for i in text if ord(i)<128)\n",
    "\n",
    "df['Person Name'] = df['Person Name'].apply(remove_non_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of characters\n",
    "# a-z, 0–9, space, dot and a special END token.\n",
    "vocab = set(' '.join([str(i) for i in df['Person Name']]))\n",
    "vocab.add('END')\n",
    "len_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab {'o', '2', 'i', '-', 'h', 'u', 'J', 'k', 'd', '?', 'U', 'n', 'f', 'P', ')', '8', '+', '!', 'l', 'w', 'c', 'q', 'I', 'K', 'N', '\"', 'B', 'M', '&', 'e', '1', '0', '_', \"'\", 'F', '$', 'L', 't', 'E', 'O', 'V', '5', 'Y', 'T', 'G', 'C', 'g', 'S', '9', ' ', 'r', '4', 'A', 'W', '7', 'D', 'X', 'R', 'H', 's', 'b', ':', '/', '.', 'a', '(', 'END', '3', 'z', 'x', 'p', 'y', 'Z', '6', 'm', ',', 'v', 'j', 'Q'}\n",
      "len_vocab 79\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab\", vocab)\n",
    "print(\"len_vocab\", len_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o': 0, '2': 1, 'i': 2, '-': 3, 'h': 4, 'u': 5, 'J': 6, 'k': 7, 'd': 8, '?': 9, 'U': 10, 'n': 11, 'f': 12, 'P': 13, ')': 14, '8': 15, '+': 16, '!': 17, 'l': 18, 'w': 19, 'c': 20, 'q': 21, 'I': 22, 'K': 23, 'N': 24, '\"': 25, 'B': 26, 'M': 27, '&': 28, 'e': 29, '1': 30, '0': 31, '_': 32, \"'\": 33, 'F': 34, '$': 35, 'L': 36, 't': 37, 'E': 38, 'O': 39, 'V': 40, '5': 41, 'Y': 42, 'T': 43, 'G': 44, 'C': 45, 'g': 46, 'S': 47, '9': 48, ' ': 49, 'r': 50, '4': 51, 'A': 52, 'W': 53, '7': 54, 'D': 55, 'X': 56, 'R': 57, 'H': 58, 's': 59, 'b': 60, ':': 61, '/': 62, '.': 63, 'a': 64, '(': 65, 'END': 66, '3': 67, 'z': 68, 'x': 69, 'p': 70, 'y': 71, 'Z': 72, '6': 73, 'm': 74, ',': 75, 'v': 76, 'j': 77, 'Q': 78}\n"
     ]
    }
   ],
   "source": [
    "char_idx = dict((c, i) for i, c in enumerate(vocab))\n",
    "print(char_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person Name    79263\n",
       "Gender         79263\n",
       "Train/Test     79263\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[df['Train/Test'].str.contains('Train')]\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person Name    19830\n",
       "Gender         19830\n",
       "Train/Test     19830\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[df['Train/Test'].str.contains('Test')]\n",
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79263,)\n",
      "(79263,)\n"
     ]
    }
   ],
   "source": [
    "feature_train = train['Person Name']\n",
    "print(feature_train.shape)\n",
    "labels_train = train['Gender']\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19830,)\n",
      "(19830,)\n"
     ]
    }
   ],
   "source": [
    "feature_test = test['Person Name']\n",
    "print(feature_test.shape)\n",
    "labels_test = test['Gender']\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take input upto max length and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#pad 'END' to shorter sequences\n",
    "maxlen = 30\n",
    "train_X = []\n",
    "trunc_train_name = [str(i)[0:30] for i in feature_train]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [char_idx[j] for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(char_idx[\"END\"])\n",
    "    train_X.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79263, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_flag(i):\n",
    "    tmp = np.zeros(79)\n",
    "    tmp[i] = 1\n",
    "    return(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_flag(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "trunc_train_name = [str(i)[0:maxlen] for i in feature_train]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [set_flag(char_idx[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_idx[\"END\"]))\n",
    "    train_X.append(tmp)\n",
    "for i in labels_train:\n",
    "    if i == 'm':\n",
    "        train_Y.append([1,0])\n",
    "    else:\n",
    "        train_Y.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79263, 30, 79)\n"
     ]
    }
   ],
   "source": [
    "#[ex, max len, vocab_len]\n",
    "print(np.asarray(train_X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model....\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model....\")\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "trunc_test_name = [str(i)[0:maxlen] for i in feature_test]\n",
    "for i in trunc_test_name:\n",
    "    tmp = [set_flag(char_idx[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_idx[\"END\"]))\n",
    "    test_X.append(tmp)\n",
    "for i in labels_test:\n",
    "    if i == 'm':\n",
    "        test_Y.append([1,0])\n",
    "    else:\n",
    "        test_Y.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19830, 30, 79)\n",
      "(19830, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(test_X).shape)\n",
    "print(np.asarray(test_Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to do this somehow values doesn't convert into numpy array\n",
    "test_X = np.array(test_X)\n",
    "test_Y = np.array(test_Y)\n",
    "train_X = np.array(train_X)\n",
    "train_Y = np.array(train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79263 samples, validate on 19830 samples\n",
      "Epoch 1/10\n",
      "79263/79263 [==============================] - 52s 650us/step - loss: 0.0158 - acc: 0.9996 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "79263/79263 [==============================] - 47s 591us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "79263/79263 [==============================] - 47s 593us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "79263/79263 [==============================] - 47s 593us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "79263/79263 [==============================] - 47s 594us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "79263/79263 [==============================] - 47s 595us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "79263/79263 [==============================] - 47s 596us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "79263/79263 [==============================] - 47s 596us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "79263/79263 [==============================] - 47s 596us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "79263/79263 [==============================] - 47s 596us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe97e3d2eb8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(train_X, train_Y,batch_size=batch_size,nb_epoch=10,validation_data=(test_X, test_Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19830/19830 [==============================] - 38s 2ms/step\n",
      "Test score: 1.1920930376163597e-07\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(test_X, test_Y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[\"Mila Kunis\",\"Jennifer Lawrence\",\"Brad Pitt\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_idx[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_idx[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.1511804e-16, 1.0000000e+00],\n",
       "       [4.1513389e-16, 1.0000000e+00],\n",
       "       [4.1512439e-16, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
